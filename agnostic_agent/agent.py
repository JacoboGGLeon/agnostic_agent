from __future__ import annotations

from typing import Any, Dict, List, Optional, Union, Tuple
from pathlib import Path
import os

import yaml
from langchain_core.messages import (
    HumanMessage,
    AIMessage,
    ToolMessage,
    AnyMessage,
)

from .capabilities import PlannerConfig, build_planner_llm
from .logic import load_logic, AgentState as State
from .communication import (
    AgentInput,
    AgentOutput,
    AgentView,
    AgentSummary,
    ToolRun,
)
from .tools import get_default_tools  # ‚úÖ cat√°logo global de tools
from .memory import read_memory, write_memory  # ‚úÖ memoria multi-nivel (in-memory)
from .context import (  # ‚úÖ KBs externas/tabulares
    KnowledgeBase,
    get_default_context,
    get_kb_by_names,
    build_kb_from_setup,
)


class Agent:
    """
    Agente agn√≥stico sobre LangGraph + Qwen3.

    Patrones de inicializaci√≥n:

        # 1) Totalmente por defecto (sin setup.yaml)
        agent = Agent.init()

        # 2) Pasando path a setup.yaml (panel de control middleware)
        agent = Agent.init("setup.yaml")
        # o bien:
        agent = Agent.init(setup_path="setup.yaml")

        # 3) Pasando un PlannerConfig expl√≠cito (ignora planner de setup.yaml)
        agent = Agent.init(PlannerConfig(temperature=0.0))

        # 4) Pasando tablas de contexto (parametr√≠as / abreviaturas, etc.)
        agent = Agent.init(
            "setup.yaml",
            context_tables=[
                "/content/parametrias.csv",
                "/content/diccionario_abreviaturas.csv",
            ],
        )

    - run_turn(...) SIEMPRE devuelve un dict:

        {
          "dev_out":  {...},  # traza completa (pipeline + raw_state)
          "deep_out": {...},  # resumen por secci√≥n (ANALYZER/PLANNER/...).
          "user_out": {...},  # respuesta 1:1 basada en herramientas.
        }

    El grafo deja en el estado:
      - tool_runs
      - summary / pipeline_summary (SummaryDict)
      - user_out / deep_out / dev_out (strings opcionales)
    y este wrapper los empaqueta en AgentOutput.

    Adem√°s:
      - Resuelve session_id / kb_names a partir de AgentInput.
      - Inyecta memory_context (read_memory) en el estado.
      - Inyecta knowledge_bases y context_tables (parametr√≠as, abreviaturas, etc.).
      - Al final de cada turno actualiza la memoria con write_memory.
    """

    def __init__(
        self,
        graph_app: Any,
        planner_config: PlannerConfig,
        tools: List[Any],
        *,
        setup_path: Optional[str] = None,
        setup_config: Optional[Dict[str, Any]] = None,
        memory_cfg: Optional[Dict[str, Any]] = None,
        knowledge_bases: Optional[List[KnowledgeBase]] = None,
        context_tables: Optional[List[str]] = None,
        context_cfg: Optional[Dict[str, Any]] = None,
    ) -> None:
        self.graph_app = graph_app
        self.planner_config = planner_config
        self.tools = tools

        # Panel de control cargado desde setup.yaml (si existe)
        self.setup_path: Optional[str] = setup_path
        self.setup_config: Dict[str, Any] = setup_config or {}

        # Config de memoria (session / short_term / long_term)
        self.memory_cfg: Dict[str, Any] = memory_cfg or {}

        # KBs registradas (tabulares, vectores, APIs, etc.)
        self.knowledge_bases: List[KnowledgeBase] = (
            knowledge_bases if knowledge_bases is not None else get_default_context()
        )

        # Tablas CSV de contexto (parametr√≠as, abreviaturas/definiciones, etc.)
        self.context_tables: List[str] = context_tables or []

        # Config de contexto crudo desde setup.yaml (opcional)
        self.context_cfg: Dict[str, Any] = context_cfg or {}

        # Estado de conversaci√≥n multi-turn (historial reducido)
        self._state: Optional[Dict[str, Any]] = None

    # ------------------------------------------------------------------
    # Helpers de setup.yaml
    # ------------------------------------------------------------------
    @staticmethod
    def _load_setup_config(
        setup_path: Optional[Union[str, Path]],
    ) -> Tuple[Optional[Path], Dict[str, Any]]:
        """
        Intenta cargar setup.yaml (o el path que se pase).

        Orden de resoluci√≥n:
          1) setup_path expl√≠cito (argumento).
          2) AGENT_SETUP_PATH en variables de entorno.
        """
        cfg: Dict[str, Any] = {}

        path_obj: Optional[Path] = None
        if isinstance(setup_path, (str, Path)):
            path_obj = Path(setup_path)
        else:
            env_path = os.getenv("AGENT_SETUP_PATH")
            if env_path:
                path_obj = Path(env_path)

        if path_obj is None:
            return None, cfg

        if not path_obj.is_file():
            # No levantamos excepci√≥n para no romper en Colab si no est√° el archivo
            print(f"[Agent] ‚ö†Ô∏è setup.yaml no encontrado en: {path_obj}. Se usar√°n defaults.")
            return path_obj, cfg

        try:
            with path_obj.open("r", encoding="utf-8") as f:
                data = yaml.safe_load(f) or {}
            if not isinstance(data, dict):
                print(f"[Agent] ‚ö†Ô∏è setup.yaml no tiene formato dict en {path_obj}. Ignorando.")
                return path_obj, {}
            cfg = data
        except Exception as e:
            print(f"[Agent] ‚ö†Ô∏è Error leyendo setup.yaml ({path_obj}): {e!r}")
            cfg = {}

        return path_obj, cfg

    @staticmethod
    def _apply_model_env_from_setup(setup_cfg: Dict[str, Any]) -> None:
        """
        Opcional: aplica variables de entorno para modelos / endpoints
        a partir de setup.yaml, sin pisar lo que ya est√© definido.
        """
        models_cfg = setup_cfg.get("models") or {}

        # LLM
        llm_cfg = models_cfg.get("llm") or {}
        llm_api_base = llm_cfg.get("api_base")
        llm_served_name = llm_cfg.get("served_name")

        if llm_api_base and "VLLM_API_BASE" not in os.environ:
            os.environ["VLLM_API_BASE"] = str(llm_api_base)
        if llm_api_base and "VLLM_LLM_API_BASE" not in os.environ:
            os.environ["VLLM_LLM_API_BASE"] = str(llm_api_base)
        if llm_served_name and "LLM_SERVED_NAME" not in os.environ:
            os.environ["LLM_SERVED_NAME"] = str(llm_served_name)

        # Embeddings
        emb_cfg = models_cfg.get("emb") or {}
        emb_api_base = emb_cfg.get("api_base")
        emb_served_name = emb_cfg.get("served_name")

        if emb_api_base and "VLLM_EMB_API_BASE" not in os.environ:
            os.environ["VLLM_EMB_API_BASE"] = str(emb_api_base)
        if emb_served_name and "EMB_SERVED_NAME" not in os.environ:
            os.environ["EMB_SERVED_NAME"] = str(emb_served_name)

        # Reranker
        rerank_cfg = models_cfg.get("rerank") or {}
        rerank_api_base = rerank_cfg.get("api_base")
        rerank_served_name = rerank_cfg.get("served_name")

        if rerank_api_base and "VLLM_RERANK_API_BASE" not in os.environ:
            os.environ["VLLM_RERANK_API_BASE"] = str(rerank_api_base)
        if rerank_served_name and "RERANK_SERVED_NAME" not in os.environ:
            os.environ["RERANK_SERVED_NAME"] = str(rerank_served_name)

        # Clave dummy para OpenAI-compatible (vLLM la ignora pero la requiere)
        if "OPENAI_API_KEY" not in os.environ:
            os.environ["OPENAI_API_KEY"] = "EMPTY"

    @staticmethod
    def _build_kb_from_setup(setup_cfg: Dict[str, Any]) -> List[KnowledgeBase]:
        """
        Construye la lista de KnowledgeBase a partir de setup.yaml usando
        el helper gen√©rico de context.build_kb_from_setup.

        Si no hay nada en el YAML, cae en get_default_context().
        """
        kb_list = build_kb_from_setup(setup_cfg)
        if not kb_list:
            kb_list = get_default_context()
        return kb_list

    @staticmethod
    def _resolve_context_tables(
        setup_cfg: Dict[str, Any],
        explicit_context_tables: Optional[List[str]],
    ) -> Tuple[List[str], Dict[str, Any]]:
        """
        Resuelve tablas de contexto (CSV) y config de contexto.

        Prioridad:
          1) context_tables expl√≠cito pasado a Agent.init(...)
          2) setup.yaml:
               context:
                 tables: [...]
               # o bien, compat:
               context_tables: [...]
        """
        context_cfg: Dict[str, Any] = setup_cfg.get("context") or {}

        yaml_tables = context_cfg.get("tables") or setup_cfg.get("context_tables") or []
        if isinstance(yaml_tables, str):
            yaml_tables = [yaml_tables]
        yaml_tables = [str(p) for p in yaml_tables] if isinstance(yaml_tables, list) else []

        if explicit_context_tables is not None:
            final_tables = list(explicit_context_tables)
        else:
            final_tables = yaml_tables

        return final_tables, context_cfg

    # ------------------------------------------------------------------
    # Factory
    # ------------------------------------------------------------------
    @classmethod
    def init(
        cls,
        config_or_setup: Optional[Union[PlannerConfig, str, os.PathLike]] = None,
        tools: Optional[List[Any]] = None,
        *,
        context_tables: Optional[List[str]] = None,
    ) -> "Agent":
        """
        Construye un Agent listo para usar.

        Patrones soportados:

            agent = Agent.init()
            agent = Agent.init("setup.yaml")
            agent = Agent.init(setup_path)  # PathLike
            agent = Agent.init(PlannerConfig(...))
            agent = Agent.init("setup.yaml", context_tables=[...])

        NOTA:
        - Si pasas PlannerConfig ‚Üí se ignora el bloque `planner` de setup.yaml.
        - Si quieres combinar ambas cosas, construye t√∫ el PlannerConfig
          leyendo el YAML y p√°salo aqu√≠.
        """
        # 1) Resolver si el primer par√°metro es un PlannerConfig o un path
        setup_path: Optional[Union[str, Path]] = None
        planner_cfg: Optional[PlannerConfig] = None

        if isinstance(config_or_setup, PlannerConfig):
            planner_cfg = config_or_setup
        elif isinstance(config_or_setup, (str, os.PathLike)):
            setup_path = config_or_setup

        # 2) Cargar setup.yaml (si existe)
        setup_path_resolved, setup_cfg = cls._load_setup_config(setup_path)

        # 3) Aplicar envs de modelos (si vienen en setup.yaml)
        if setup_cfg:
            cls._apply_model_env_from_setup(setup_cfg)

        # 4) PlannerConfig: o bien el expl√≠cito, o bien override desde YAML
        if planner_cfg is not None:
            cfg = planner_cfg
        else:
            cfg = PlannerConfig()
            planner_section = setup_cfg.get("planner") or {}
            # Sobrescribimos s√≥lo campos conocidos (tolerante)
            for key, value in planner_section.items():
                if hasattr(cfg, key):
                    setattr(cfg, key, value)

        # 5) Tools: prioridad al par√°metro expl√≠cito; si no, leer de setup.yaml
        if tools is not None:
            tools_list = tools
        else:
            tools_section = setup_cfg.get("tools") or {}
            enabled_names = tools_section.get("enabled")
            tools_list = get_default_tools(enabled_names=enabled_names)

        # 6) LLM planner bindeado a las tools
        planner_llm = build_planner_llm(cfg)
        planner_llm = planner_llm.bind_tools(tools_list)

        # 7) Construir grafo principal
        graph_app = load_logic(
            planner_llm=planner_llm,
            tools=tools_list,
            planner_config=cfg,
        )

        # 8) Config de memoria desde setup.yaml (si existe)
        memory_cfg = setup_cfg.get("memory") or {}

        # 9) Knowledge Bases (tabulares / vectores / APIs) desde setup.yaml
        kb_list = cls._build_kb_from_setup(setup_cfg)

        # 10) Tablas de contexto (parametr√≠as, abreviaturas, etc.)
        final_context_tables, context_cfg = cls._resolve_context_tables(
            setup_cfg=setup_cfg,
            explicit_context_tables=context_tables,
        )

        return cls(
            graph_app=graph_app,
            planner_config=cfg,
            tools=tools_list,
            setup_path=str(setup_path_resolved) if setup_path_resolved else None,
            setup_config=setup_cfg,
            memory_cfg=memory_cfg,
            knowledge_bases=kb_list,
            context_tables=final_context_tables,
            context_cfg=context_cfg,
        )

    # ------------------------------------------------------------------
    # Helpers internos
    # ------------------------------------------------------------------
    def _coerce_input(
        self,
        user_input: Union[str, Dict[str, Any], AgentInput],
    ) -> AgentInput:
        """
        Normaliza la entrada a AgentInput:

        - str  -> AgentInput(user_prompt=...)
        - dict -> AgentInput(**dict)
        - AgentInput -> se respeta tal cual
        """
        if isinstance(user_input, AgentInput):
            return user_input
        if isinstance(user_input, dict):
            return AgentInput(**user_input)
        return AgentInput(user_prompt=str(user_input))

    def _clean_prev_messages(self) -> List[AnyMessage]:
        """
        Limpia el historial previo para evitar ToolMessages gigantes en turnos futuros.
        """
        msgs: List[AnyMessage] = []
        if self._state is None:
            return msgs

        for m in self._state.get("messages", []):
            # ‚ùå No arrastramos ToolMessages con JSONs enormes
            if isinstance(m, ToolMessage):
                continue
            msgs.append(m)
        return msgs

    def _build_deep_text(
        self,
        summary_obj: Optional[AgentSummary],
    ) -> str:
        """
        Construye la vista 'deep' (resumen por secci√≥n) a partir de AgentSummary.

        - No incluye el raw_state completo.
        - Es m√°s compacta que la traza dev_out, pero sigue seccionada.
        """
        if summary_obj is None:
            # Si por alguna raz√≥n no hay summary, devolvemos cadena vac√≠a;
            # el caller puede hacer fallback.
            return ""

        parts: List[str] = ["## Resumen deep del pipeline"]

        if summary_obj.analyzer:
            parts.append("### ANALYZER\n" + summary_obj.analyzer)
        if summary_obj.planner:
            parts.append("### PLANNER\n" + summary_obj.planner)
        if summary_obj.executor:
            parts.append("### EXECUTOR\n" + summary_obj.executor)
        if summary_obj.catcher:
            parts.append("### CATCHER\n" + summary_obj.catcher)
        if summary_obj.summarizer:
            parts.append("### SUMMARIZER (basado en herramientas)\n" + summary_obj.summarizer)
        if summary_obj.final_answer:
            parts.append("### RESPUESTA FINAL\n" + summary_obj.final_answer)

        return "\n\n".join(parts)

    # ------------------------------------------------------------------
    # API p√∫blico
    # ------------------------------------------------------------------
    def run_turn(
        self,
        user_input: Union[str, Dict[str, Any], AgentInput],
    ) -> Dict[str, Any]:
        """
        Ejecuta un turno de conversaci√≥n.

        Devuelve SIEMPRE un dict:

            {
              "dev_out": {
                  "final_answer": "...pipeline markdown (traza completa)...",
                  "summary": {...},
                  "tool_runs": [...],
                  "raw_state": {...}   # estado crudo del grafo
              },
              "deep_out": {
                  "final_answer": "...resumen por secci√≥n...",
                  "summary": {...},
                  "tool_runs": [...],
                  "raw_state": {}      # vista ligera
              },
              "user_out": {
                  "final_answer": "...respuesta para usuario (1:1)...",
                  "summary": {...},
                  "tool_runs": [...],
                  "raw_state": {}
              }
            }
        """
        agent_in = self._coerce_input(user_input)

        # Texto can√≥nico del prompt (user_prompt > user_text como fallback)
        prompt_text = (
            getattr(agent_in, "user_prompt", None)
            or getattr(agent_in, "user_text", None)
            or ""
        )

        # -------------------------
        # 0) Resolver session_id / user_id / kb_names
        # -------------------------
        session_id = agent_in.session_id or "default"
        user_id = None
        if agent_in.metadata:
            user_id = agent_in.metadata.get("user_id")

        kb_names = agent_in.kb_names or []

        # Seleccionar KBs activas para este turno (si kb_names est√° vac√≠o, usamos todas)
        kb_selected = get_kb_by_names(kb_names, self.knowledge_bases)

        # -------------------------
        # 1) Leer memoria para esta sesi√≥n
        # -------------------------
        memory_context = read_memory(session_id=session_id)

        # 2) Construir estado de entrada al grafo
        prev_messages = self._clean_prev_messages()
        state_in: State = {
            "messages": prev_messages + [HumanMessage(content=prompt_text)],
            "analyzer": None,
            "planner_trajs": [],
            "executor_steps": [],
            "tool_runs": [],
            "summary": None,
            "pipeline_summary": None,
            # Campos extra (no tipados en State, pero soportados por TypedDict total=False)
            "user_prompt": prompt_text,
            "session_id": session_id,
            "user_id": user_id,
            "setup_path": self.setup_path or "",
            "setup_config": self.setup_config,  # üëà YAML completo (por si lo necesita el grafo)
            "kb_names": kb_names,
            "kb_all": [kb.__dict__ for kb in self.knowledge_bases],
            "kb_selected": [kb.__dict__ for kb in kb_selected],
            "memory_context": memory_context,
            # Tablas de contexto (para semantic_search_in_csv en el grafo)
            "context_tables": list(self.context_tables),
            "context_cfg": self.context_cfg,
        }

        # 3) Invocar grafo
        out_state: State = self.graph_app.invoke(state_in)
        self._state = out_state  # guardamos para multi-turn

        # 4) Extraer √∫ltimo AIMessage (por si no vienen campos dev_out/deep_out en state)
        ai_messages = [
            m for m in out_state.get("messages", []) if isinstance(m, AIMessage)
        ]
        last_ai = ai_messages[-1] if ai_messages else None
        last_ai_text = last_ai.content if last_ai is not None else ""

        # 5) Campos de texto que el grafo ya pudo haber dejado en el estado
        dev_text_state = out_state.get("dev_out")  # type: ignore[assignment]
        deep_text_state = out_state.get("deep_out")  # type: ignore[assignment]
        user_text_state = out_state.get("user_out")  # type: ignore[assignment]

        # 6) Summary estructurado (con final_answer "para usuario")
        raw_summary: Dict[str, Any] = (
            out_state.get("pipeline_summary")  # type: ignore[arg-type]
            or out_state.get("summary")  # type: ignore[arg-type]
            or {}
        )
        if raw_summary:
            summary_obj = AgentSummary(**raw_summary)
            summary_user_answer = summary_obj.final_answer or ""
        else:
            summary_obj = None
            summary_user_answer = ""

        # 7) Tool runs normalizados (para las tres vistas)
        raw_runs = out_state.get("tool_runs", []) or []
        tool_runs: List[ToolRun] = []
        for r in raw_runs:
            tool_runs.append(
                ToolRun(
                    id=str(r.get("id", "")),
                    name=str(r.get("name", "")),
                    args=r.get("args", {}),
                    output=r.get("output"),
                )
            )

        # 8) Resolver textos finales por vista con prioridades claras
        # USER:
        #   1) user_text_state (si el grafo lo puso)
        #   2) summary_user_answer (si existe en AgentSummary)
        #   3) last_ai_text (√∫ltimo mensaje de la traza)
        final_user = (
            (user_text_state or "").strip()
            or summary_user_answer.strip()
            or last_ai_text.strip()
        )

        # DEEP:
        #   1) deep_text_state (del grafo)
        #   2) _build_deep_text(summary_obj)
        #   3) summary_user_answer
        final_deep = (
            (deep_text_state or "").strip()
            or self._build_deep_text(summary_obj).strip()
            or summary_user_answer.strip()
            or last_ai_text.strip()
        )

        # DEV:
        #   1) dev_text_state (del grafo: traza markdown completa)
        #   2) last_ai_text
        #   3) deep_text (como fallback)
        final_dev = (
            (dev_text_state or "").strip()
            or last_ai_text.strip()
            or final_deep
        )

        # 9) Construir vistas
        dev_view = AgentView(
            final_answer=final_dev,
            summary=summary_obj,
            tool_runs=tool_runs,
            raw_state=out_state,  # vista completa
        )

        deep_view = AgentView(
            final_answer=final_deep,
            summary=summary_obj,
            tool_runs=tool_runs,
            raw_state={},  # light view
        )

        user_view = AgentView(
            final_answer=final_user,
            summary=summary_obj,
            tool_runs=tool_runs,
            raw_state={},  # usuario nunca necesita estado crudo
        )

        # 10) Actualizar memoria de largo/corto plazo
        try:
            write_memory(
                session_id=session_id,
                user_prompt=prompt_text,
                user_out=final_user,
                user_id=user_id,
                memory_cfg=self.memory_cfg,
            )
        except Exception as e:
            # No queremos que un fallo en memoria rompa el turno
            print(f"[Agent] ‚ö†Ô∏è Error escribiendo memoria: {e!r}")

        # 11) Empaquetar en AgentOutput y devolver como dict puro
        output = AgentOutput(
            dev_out=dev_view,
            deep_out=deep_view,
            user_out=user_view,
        )
        return output.to_dict()

    # ------------------------------------------------------------------
    # Extras √∫tiles para debugging
    # ------------------------------------------------------------------
    @property
    def last_state(self) -> Optional[Dict[str, Any]]:
        """Devuelve el √∫ltimo estado crudo del grafo (solo lectura)."""
        return self._state

    def reset_session(self) -> None:
        """Resetea el estado interno de conversaci√≥n (no borra memoria global)."""
        self._state = None
